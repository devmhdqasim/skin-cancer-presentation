<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Skin Cancer Detection and Classification using Deep Learning</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: #333;
            overflow-x: hidden;
            line-height: 1.6;
        }

        .presentation-container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
        }

        .slide {
            background: white;
            margin: 30px 0;
            padding: 50px;
            border-radius: 15px;
            box-shadow: 0 10px 30px rgba(0,0,0,0.2);
            min-height: 85vh;
            display: flex;
            flex-direction: column;
            justify-content: center;
            page-break-after: always;
            border-left: 6px solid #4CAF50;
        }

        .slide-number {
            position: absolute;
            top: 15px;
            right: 25px;
            background: #4CAF50;
            color: white;
            padding: 8px 15px;
            border-radius: 20px;
            font-size: 14px;
            font-weight: bold;
        }

        h1 {
            color: #2c3e50;
            text-align: center;
            margin-bottom: 40px;
            font-size: 2.8em;
            border-bottom: 3px solid #4CAF50;
            padding-bottom: 20px;
            line-height: 1.4;
        }

        h2 {
            color: #34495e;
            margin-bottom: 30px;
            font-size: 2.2em;
            border-left: 5px solid #4CAF50;
            padding-left: 25px;
            line-height: 1.4;
        }

        h3 {
            color: #4CAF50;
            margin-bottom: 20px;
            font-size: 1.6em;
            line-height: 1.4;
        }

        .title-slide {
            text-align: center;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            border-left: none;
        }

        .title-slide h1 {
            color: white;
            font-size: 3.2em;
            margin-bottom: 50px;
            border-bottom: 3px solid white;
        }

        .author-info {
            margin-top: 50px;
            font-size: 1.3em;
            line-height: 1.8;
        }

        ul {
            list-style: none;
            padding-left: 0;
            line-height: 1.8;
        }

        li {
            margin: 20px 0;
            padding: 15px 25px 15px 45px;
            background: #f8f9fa;
            border-left: 4px solid #4CAF50;
            border-radius: 8px;
            position: relative;
            font-size: 1.1em;
            line-height: 1.6;
        }

        li:before {
            content: "‚ñ∂";
            color: #4CAF50;
            font-weight: bold;
            position: absolute;
            left: 15px;
            top: 50%;
            transform: translateY(-50%);
        }

        .stats-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(280px, 1fr));
            gap: 25px;
            margin: 30px 0;
        }

        .stat-card {
            background: #e8f5e8;
            padding: 25px;
            border-radius: 12px;
            text-align: center;
            border: 2px solid #4CAF50;
            line-height: 1.5;
        }

        .stat-number {
            font-size: 2.5em;
            font-weight: bold;
            color: #4CAF50;
            margin-bottom: 10px;
        }

        .methodology-flow {
            display: flex;
            justify-content: space-between;
            align-items: center;
            margin: 40px 0;
            flex-wrap: wrap;
        }

        .flow-step {
            background: #4CAF50;
            color: white;
            padding: 20px 25px;
            border-radius: 12px;
            margin: 15px;
            text-align: center;
            flex: 1;
            min-width: 180px;
            position: relative;
            font-size: 1.1em;
            line-height: 1.4;
        }

        .flow-step:not(:last-child):after {
            content: "‚Üí";
            position: absolute;
            right: -20px;
            color: #4CAF50;
            font-size: 1.8em;
            font-weight: bold;
        }

        .highlight-box {
            background: #fff3cd;
            border: 2px solid #ffc107;
            border-radius: 12px;
            padding: 25px;
            margin: 25px 0;
            line-height: 1.6;
        }

        .problem-box {
            background: #f8d7da;
            border: 2px solid #dc3545;
            border-radius: 12px;
            padding: 25px;
            margin: 25px 0;
            line-height: 1.6;
        }

        .solution-box {
            background: #d1ecf1;
            border: 2px solid #0dcaf0;
            border-radius: 12px;
            padding: 25px;
            margin: 25px 0;
            line-height: 1.6;
        }

        .references {
            font-size: 1em;
            line-height: 1.8;
            columns: 2;
            column-gap: 40px;
        }

        .download-btn {
            position: fixed;
            bottom: 30px;
            right: 30px;
            background: #4CAF50;
            color: white;
            padding: 15px 25px;
            border: none;
            border-radius: 50px;
            cursor: pointer;
            font-size: 16px;
            box-shadow: 0 5px 15px rgba(0,0,0,0.3);
            z-index: 1000;
        }

        .download-btn:hover {
            background: #45a049;
            transform: translateY(-2px);
        }

        @media print {
            body { background: white; }
            .slide { box-shadow: none; margin: 0; page-break-after: always; }
            .download-btn { display: none; }
        }

        .research-questions {
            background: #e3f2fd;
            border-left: 6px solid #2196F3;
            padding: 25px;
            margin: 25px 0;
            border-radius: 8px;
            line-height: 1.6;
        }

        .two-column {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 30px;
            margin: 25px 0;
        }

        .column-box {
            background: #f0f8ff;
            padding: 25px;
            border-radius: 12px;
            border: 2px solid #4169e1;
            line-height: 1.6;
        }

        .quote-text {
            font-style: italic;
            font-size: 1.1em;
            color: #555;
            padding: 20px;
            background: #f8f9fa;
            border-left: 4px solid #4CAF50;
            margin: 20px 0;
            line-height: 1.6;
        }
    </style>
</head>
<body>
    <div class="presentation-container">
        
        <!-- Slide 1: Title -->
        <div class="slide title-slide">
            <div class="slide-number">1</div>
            <h1>Intelligent Skin Lesion Detection and Classification using Deep Learning in Dermoscopic Images</h1>
            <div class="author-info">
                <p><strong>Submitted by: Saira Asghar</strong></p>
                <p>MS Data Science</p>
                <br>
                <p><strong>Supervisor:</strong> Dr. Saleem Mustafa</p>
                <br>
                <p>Department of Data Science</p>
                <p>Superior University, Gold Campus, Lahore</p>
            </div>
        </div>

        <!-- Slide 2: Introduction & Problem Overview -->
        <div class="slide">
            <div class="slide-number">2</div>
            <h2>Introduction & Problem Overview</h2>
            
            <div class="highlight-box">
                <h3>What is Melanoma?</h3>
                <p class="quote-text">"Melanoma is skin lesion, which contain melanocytes in pigment-cells of the skin body which has significant dominance amongst the patients of skin lesion."</p>
            </div>

            <div class="stats-grid">
                <div class="stat-card">
                    <div class="stat-number">300,000</div>
                    <p>New cases in 2018 globally</p>
                </div>
                <div class="stat-card">
                    <div class="stat-number">15th</div>
                    <p>Most commonly occurring cancer in men and women</p>
                </div>
                <div class="stat-card">
                    <div class="stat-number">75%</div>
                    <p>Of skin cancer mortality caused by melanoma</p>
                </div>
            </div>
        </div>

        <!-- Slide 3: Critical Statistics -->
        <div class="slide">
            <div class="slide-number">3</div>
            <h2>Critical Impact of Early Detection</h2>
            
            <div class="two-column">
                <div class="column-box">
                    <h3>Survival Rates by Stage</h3>
                    <ul>
                        <li>Stage I (less than 0.76mm thick): <strong>96% 5-year survival rate</strong></li>
                        <li>Stage IV: <strong>Only 5% 5-year survival rate</strong></li>
                        <li>Average survival rate if late detected: 6 to 9 months</li>
                    </ul>
                </div>
                
                <div class="column-box">
                    <h3>Economic Impact</h3>
                    <ul>
                        <li>Stage IV treatment cost is <strong>30 times more</strong> than Stage I</li>
                        <li>Most common cancer in adults aged 15-30</li>
                        <li>Death rate 3 times more than all other skin-related malignancies</li>
                    </ul>
                </div>
            </div>

            <div class="solution-box">
                <h3>Geographic Distribution Patterns</h3>
                <ul>
                    <li><strong>Males:</strong> Commonly on head, neck, or between hips and shoulders</li>
                    <li><strong>Females:</strong> Generally on legs or between hips and shoulders</li>
                    <li><strong>Dark-skinned individuals:</strong> Under fingernails, toenails, palms, and feet soles</li>
                </ul>
            </div>
        </div>

        <!-- Slide 4: Current Challenges -->
        <div class="slide">
            <div class="slide-number">4</div>
            <h2>Current Diagnostic Challenges</h2>
            
            <div class="problem-box">
                <h3>Manual Diagnosis Limitations</h3>
                <ul>
                    <li>ABCD rule with dermoscopy shows sensitivity of <strong>76.0-87.7%</strong> and specificity of <strong>61.0-77.8%</strong></li>
                    <li>Only <strong>48% of dermatologists</strong> in the United States use dermoscopic devices</li>
                    <li>Lack of training or interest causes low adoption rates</li>
                </ul>
            </div>

            <div class="highlight-box">
                <h3>Technical Challenges in Dermoscopic Images</h3>
                <ul>
                    <li><strong>Noise artifacts:</strong> Shadows, low contrast between lesion and healthy skin</li>
                    <li><strong>Hair presence:</strong> Complicates lesion boundary detection</li>
                    <li><strong>Illumination variations:</strong> Affects image quality and analysis</li>
                    <li><strong>Specular reflections:</strong> Creates additional noise in images</li>
                </ul>
            </div>

            <div class="solution-box">
                <h3>Need for Automation</h3>
                <p>"Existing systems on skin lesion for detection and classification are also computationally extensive and quite costly. Our proposed research work will solve these problems by designing a computationally, economically and an efficient system."</p>
            </div>
        </div>

        <!-- Slide 5: Research Questions & Objectives -->
        <div class="slide">
            <div class="slide-number">5</div>
            <h2>Research Questions & Objectives</h2>
            
            <div class="research-questions">
                <h3>Primary Research Questions</h3>
                <ul>
                    <li>What are the techniques for skin lesion detection from dermoscopic images?</li>
                    <li>Which color transformation is suitable for skin lesion detection?</li>
                    <li>What types of features are suitable for classification of skin lesions?</li>
                    <li>What are the techniques for pre-processing like hair removal and illumination effects?</li>
                </ul>
            </div>

            <div class="solution-box">
                <h3>Research Objectives</h3>
                <ul>
                    <li>Propose automated and intelligent system to remove artifacts</li>
                    <li>Develop segmentation methods for correct lesion parts</li>
                    <li>Extract lesion features using advanced techniques</li>
                    <li>Use classifier techniques to classify the type of lesion</li>
                </ul>
            </div>
        </div>

        <!-- Slide 6: Proposed Methodology -->
        <div class="slide">
            <div class="slide-number">6</div>
            <h2>Proposed Deep Learning Methodology</h2>
            
            <div class="methodology-flow">
                <div class="flow-step">Pre-processing</div>
                <div class="flow-step">Segmentation</div>
                <div class="flow-step">Feature Extraction</div>
                <div class="flow-step">Classification</div>
            </div>

            <div class="highlight-box">
                <h3>Four Main Phases</h3>
                <p>"The proposed methodology will consist of four main phases namely pre-processing to remove noise, shadows, hairs or illumination effects. Color space transformation, extraction of color and texture features, and classification."</p>
            </div>

            <div class="two-column">
                <div class="column-box">
                    <h3>Deep Learning Components</h3>
                    <ul>
                        <li>Convolutional Neural Networks (CNNs)</li>
                        <li>Transfer Learning approaches</li>
                        <li>Ensemble methods</li>
                        <li>Automated feature extraction</li>
                    </ul>
                </div>
                
                <div class="column-box">
                    <h3>Decision Support Integration</h3>
                    <ul>
                        <li>Human expert knowledge</li>
                        <li>Patient follow-up history</li>
                        <li>Multi-classifier voting</li>
                        <li>Confidence measures</li>
                    </ul>
                </div>
            </div>
        </div>

        <!-- Slide 7: Pre-processing Phase -->
        <div class="slide">
            <div class="slide-number">7</div>
            <h2>Pre-processing & Image Enhancement</h2>
            
            <div class="solution-box">
                <h3>Hair Removal Technique</h3>
                <p>"In our approach and with the purpose of enhancing the image quality, the Directional Gabor filters are implemented to extract hair artifact from dermoscopic images. However, the parameters used in the Gaussian filters at each stage are different."</p>
            </div>

            <div class="two-column">
                <div class="column-box">
                    <h3>Noise Removal Methods</h3>
                    <ul>
                        <li><strong>Directional Gabor Filters:</strong> Extract hair artifacts effectively</li>
                        <li><strong>Gaussian Filters:</strong> Different parameters for each processing stage</li>
                        <li><strong>Shadow Removal:</strong> Eliminate illumination variations</li>
                        <li><strong>Contrast Enhancement:</strong> Improve lesion visibility</li>
                    </ul>
                </div>
                
                <div class="column-box">
                    <h3>Image Quality Assessment</h3>
                    <ul>
                        <li>Check if image enhancement is required</li>
                        <li>Improve and enhance image quality when needed</li>
                        <li>Standardize image properties</li>
                        <li>Prepare images for segmentation phase</li>
                    </ul>
                </div>
            </div>

            <div class="highlight-box">
                <h3>Why Pre-processing is Critical</h3>
                <p>"Due to the existence of noise such as shadows, low contrast of lesion portion and healthy skin, hairs, illumination variation hairs and specular reflections, the existing algorithm for skin lesion segmentation are affected."</p>
            </div>
        </div>

        <!-- Slide 8: Segmentation & Feature Extraction -->
        <div class="slide">
            <div class="slide-number">8</div>
            <h2>Advanced Segmentation & Feature Extraction</h2>
            
            <div class="problem-box">
                <h3>Segmentation Challenge</h3>
                <p>"The overall presence of the skin lesion could be erroneously considered the same color for different patients, however the absolute values of these colors varies among various patients."</p>
            </div>

            <div class="solution-box">
                <h3>Proposed Segmentation Approach</h3>
                <ul>
                    <li><strong>Genetic Algorithm based Adaptive Thresholding:</strong> Using Gaussian Histogram</li>
                    <li><strong>Adaptive Incremental Snake Region Growing:</strong> For precise boundary detection</li>
                    <li>Better than traditional iterative thresholding based on mean values</li>
                </ul>
            </div>

            <div class="two-column">
                <div class="column-box">
                    <h3>Multi-Feature Extraction</h3>
                    <ul>
                        <li><strong>Texture:</strong> G-LBP, LBP, Gabor Filters, HOG, MCHOG</li>
                        <li><strong>Color:</strong> Color model selection, Chromatic features, Statistical moments</li>
                        <li><strong>Shape:</strong> Geometrical features, ABCD parameters</li>
                    </ul>
                </div>
                
                <div class="column-box">
                    <h3>Deep Learning Features</h3>
                    <ul>
                        <li>CNN feature maps for automated learning</li>
                        <li>Transfer learning from pre-trained models</li>
                        <li>Multi-scale feature analysis</li>
                        <li>Attention mechanisms for important regions</li>
                    </ul>
                </div>
            </div>
        </div>

        <!-- Slide 9: Classification Framework -->
        <div class="slide">
            <div class="slide-number">9</div>
            <h2>Multi-Classifier Deep Learning Framework</h2>
            
            <div class="highlight-box">
                <h3>Ensemble Learning Strategy</h3>
                <p>"One way to force a learning algorithm to construct multiple hypotheses is to run the algorithm several times and provide it with somewhat different data in each run. We will use Majority Voting."</p>
            </div>

            <div class="stats-grid">
                <div class="stat-card">
                    <div class="stat-number">C‚ÇÅ</div>
                    <p>Artificial Neural Networks (ANN)</p>
                </div>
                <div class="stat-card">
                    <div class="stat-number">C‚ÇÇ</div>
                    <p>Bayesian Networks</p>
                </div>
                <div class="stat-card">
                    <div class="stat-number">C‚ÇÉ</div>
                    <p>Decision Trees</p>
                </div>
                <div class="stat-card">
                    <div class="stat-number">C‚ÇÑ</div>
                    <p>K-Nearest Neighbors (KNN)</p>
                </div>
            </div>

            <div class="solution-box">
                <h3>Deep Learning Integration</h3>
                <ul>
                    <li>Custom CNN architectures for dermoscopic images</li>
                    <li>Transfer learning with fine-tuning capabilities</li>
                    <li>Data augmentation for improved generalization</li>
                    <li>Ensemble voting for final classification decision</li>
                </ul>
            </div>
        </div>

        <!-- Slide 10: Research Scope & Expected Results -->
        <div class="slide">
            <div class="slide-number">10</div>
            <h2>Research Scope & Expected Outcomes</h2>
            
            <div class="two-column">
                <div class="column-box">
                    <h3>Research Scope</h3>
                    <ul>
                        <li>Focus on identifying <strong>various categories of lesion</strong> vs. limited classes</li>
                        <li>Integration of human expert knowledge with AI</li>
                        <li>Novel computational intelligence techniques</li>
                        <li>Comparison with state-of-the-art systems</li>
                    </ul>
                </div>
                
                <div class="column-box">
                    <h3>Key Improvements</h3>
                    <ul>
                        <li>Higher accuracy than existing manual diagnosis</li>
                        <li>Reduced computational complexity</li>
                        <li>Multi-class lesion classification capability</li>
                        <li>Cost-effective automated screening</li>
                    </ul>
                </div>
            </div>

            <div class="highlight-box">
                <h3>Advantages Over Existing Systems</h3>
                <p>"Color features are stronger candidates to provide more discrimination power as compared to textual features. Existing methods in this area are computationally extensive because they use large category of features."</p>
            </div>

            <div class="solution-box">
                <h3>Expected Impact</h3>
                <ul>
                    <li><strong>Medical Decision Support:</strong> Assists medical staff in important decisions</li>
                    <li><strong>Improved Accessibility:</strong> Expert-level diagnosis in underserved areas</li>
                    <li><strong>Cost Reduction:</strong> Lower healthcare costs through early detection</li>
                    <li><strong>Life-Saving Potential:</strong> Better patient outcomes through timely diagnosis</li>
                </ul>
            </div>
        </div>

        <!-- Slide 11: Future Directions & Conclusion -->
        <div class="slide">
            <div class="slide-number">11</div>
            <h2>Future Directions & Conclusion</h2>
            
            <div class="solution-box">
                <h3>Future Research Directions</h3>
                <ul>
                    <li><strong>3D Lesion Analysis:</strong> Integration of depth information</li>
                    <li><strong>Mobile Applications:</strong> Real-time smartphone-based diagnosis</li>
                    <li><strong>Multi-Modal Imaging:</strong> Combining different imaging techniques</li>
                    <li><strong>Federated Learning:</strong> Privacy-preserving collaborative training</li>
                </ul>
            </div>

            <div class="highlight-box">
                <h3>Research Contributions</h3>
                <ul>
                    <li>Novel deep learning framework for dermoscopic image analysis</li>
                    <li>Comprehensive integration of traditional and AI-based features</li>
                    <li>Computationally efficient algorithms for practical deployment</li>
                    <li>Medical decision support system with expert knowledge integration</li>
                </ul>
            </div>

            <div class="stats-grid">
                <div class="stat-card">
                    <div class="stat-number">Early Detection</div>
                    <p>Saves Lives & Reduces Costs</p>
                </div>
                <div class="stat-card">
                    <div class="stat-number">AI Integration</div>
                    <p>Enhances Diagnostic Accuracy</p>
                </div>
                <div class="stat-card">
                    <div class="stat-number">Automated System</div>
                    <p>Accessible Healthcare Solution</p>
                </div>
            </div>
        </div>

        <!-- Slide 12: References -->
        <div class="slide">
            <div class="slide-number">12</div>
            <h2>Key References</h2>
            <div class="references">
                <p>[1] Jerant, Anthony F., et al. "Early detection and treatment of skin cancer." American family physician 62, no. 2 (2000): 357-386.</p>
                
                <p>[2] Vestergaard, M. E., et al. "Dermoscopy compared with naked eye examination for the diagnosis of primary melanoma." British Journal of Dermatology 159, no. 3 (2008): 669-676.</p>
                
                <p>[3] Celebi, M. Emre, et al. "Lesion border detection in dermoscopy images." Computerized medical imaging and graphics 33, no. 2 (2009): 148-153.</p>
                
                <p>[4] Silveira, Margarida, et al. "Comparison of segmentation methods for melanoma diagnosis in dermoscopy images." IEEE Journal of Selected Topics in Signal Processing 3, no. 1 (2009): 35-45.</p>
                
                <p>[5] Argenziano, Giuseppe, et al. "Dermoscopy of pigmented skin lesions: results of a consensus meeting via the Internet." Journal of the American Academy of Dermatology 48, no. 5 (2003): 679-693.</p>
                
                <p>[6] Dhawan, Atam P., and Anne Sim. "Segmentation of images of skin lesions using color and texture information." Computerized Medical Imaging and Graphics 16, no. 3 (1992): 163-177.</p>
                
                <p>[7] Stoecker, William V., et al. "Texture in skin images: comparison of three methods to determine smoothness." Computerized medical imaging and graphics 16, no. 3 (1992): 179-190.</p>
                
                <p>[8] Public Health Agency of Canada, "Melanoma skin cancer," 2013.</p>
            </div>
            
            <div class="author-info" style="margin-top: 40px; text-align: center; color: #4CAF50;">
                <p><strong>Thank You for Your Attention</strong></p>
                <p><em>Questions & Discussion Welcome</em></p>
            </div>
        </div>

    </div>

    <button class="download-btn" onclick="downloadPresentation()">üì• Download as PDF</button>

    <script>
        function downloadPresentation() {
            document.querySelector('.download-btn').style.display = 'none';
            window.print();
            setTimeout(() => {
                document.querySelector('.download-btn').style.display = 'block';
            }, 1000);
        }

        document.addEventListener('DOMContentLoaded', function() {
            const slides = document.querySelectorAll('.slide');
            slides.forEach((slide, index) => {
                slide.addEventListener('click', function(e) {
                    if (e.target.closest('.download-btn')) return;
                    
                    const nextSlide = slides[index + 1];
                    if (nextSlide) {
                        nextSlide.scrollIntoView({ behavior: 'smooth' });
                    }
                });
            });

            document.addEventListener('keydown', function(e) {
                if (e.key === 'ArrowDown' || e.key === 'PageDown') {
                    e.preventDefault();
                    const currentSlide = getCurrentSlide();
                    const nextSlide = slides[currentSlide + 1];
                    if (nextSlide) {
                        nextSlide.scrollIntoView({ behavior: 'smooth' });
                    }
                } else if (e.key === 'ArrowUp' || e.key === 'PageUp') {
                    e.preventDefault();
                    const currentSlide = getCurrentSlide();
                    const prevSlide = slides[currentSlide - 1];
                    if (prevSlide) {
                        prevSlide.scrollIntoView({ behavior: 'smooth' });
                    }
                }
            });

            function getCurrentSlide() {
                const scrollPosition = window.scrollY + window.innerHeight / 2;
                for (let i = 0; i < slides.length; i++) {
                    const slideTop = slides[i].offsetTop;
                    const slideBottom = slideTop + slides[i].offsetHeight;
                    if (scrollPosition >= slideTop && scrollPosition <= slideBottom) {
                        return i;
                    }
                }
                return 0;
            }
        });
    </script>
</body>
</html>
